{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "\n",
    "# Load the jpg files into numpy arrays\n",
    "biden_image = face_recognition.load_image_file(\"biden.jpg\")\n",
    "obama_image = face_recognition.load_image_file(\"obama.jpg\")\n",
    "unknown_image = face_recognition.load_image_file(\"obama2.jpg\")\n",
    "\n",
    "# Get the face encodings for each face in each image file\n",
    "# Since there could be more than one face in each image, it returns a list of encodings.\n",
    "# But since I know each image only has one face, I only care about the first encoding in each image, so I grab index 0.\n",
    "try:\n",
    "    biden_face_encoding = face_recognition.face_encodings(biden_image)[0]\n",
    "    obama_face_encoding = face_recognition.face_encodings(obama_image)[0]\n",
    "    unknown_face_encoding = face_recognition.face_encodings(unknown_image)[0]\n",
    "except IndexError:\n",
    "    print(\"I wasn't able to locate any faces in at least one of the images. Check the image files. Aborting...\")\n",
    "    quit()\n",
    "\n",
    "known_faces = [\n",
    "    biden_face_encoding,\n",
    "    obama_face_encoding\n",
    "]\n",
    "\n",
    "# results is an array of True/False telling if the unknown face matched anyone in the known_faces array\n",
    "results = face_recognition.compare_faces(known_faces, unknown_face_encoding)\n",
    "\n",
    "print(\"Is the unknown face a picture of Biden? {}\".format(results[0]))\n",
    "print(\"Is the unknown face a picture of Obama? {}\".format(results[1]))\n",
    "print(\"Is the unknown face a new person that we've never seen before? {}\".format(not True in results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import os\n",
    "path_to_dataset = '/home/lee/dataset/CK+/subject-images'\n",
    "subjects = os.listdir(path_to_dataset)\n",
    "subject_images = []\n",
    "for s in subjects:\n",
    "    sub_folder = os.listdir(path_to_dataset + '/' + s)\n",
    "    for sf in sub_folder:\n",
    "        for pic in os.listdir(path_to_dataset + '/' + s + '/' + sf):\n",
    "            if(pic.split('.')[1] != 'db' and pic.split('.')[1] != 'pts'):\n",
    "#                 print(pic)\n",
    "                tmp_image = face_recognition.load_image_file(path_to_dataset + '/' + s + '/' + sf +'/' + pic)\n",
    "                subject_images.append([face_recognition.face_encodings(tmp_image)[0], s])\n",
    "                break\n",
    "\n",
    "        \n",
    "            \n",
    "    \n",
    "#     for sf in sub_folder:\n",
    "#         images  = os.listdir(path_to_dataset + '/' + s + '/' + sf)\n",
    "#         for i in images:\n",
    "#             if(i.split('.')[1] != 'pts' and i != 'Thumbs.db'):\n",
    "#                 tmp_image = face_recognition.load_image_file(path_to_dataset + '/' + s + '/' + sf +'/' + i)\n",
    "#                 subject_images.append([face_recognition.face_encodings(tmp_image)[0], s])\n",
    "#                 break\n",
    "\n",
    "# print(subject_images)\n",
    "known_faces = []\n",
    "for si in subject_images:\n",
    "    known_faces.append(si[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kien']\n",
      "[-0.10575922  0.09650114 -0.0073488  -0.06721263 -0.08826589 -0.04560251\n",
      " -0.08840216 -0.13951473  0.10377172 -0.10629282  0.19541229 -0.04173768\n",
      " -0.23411161 -0.0978996  -0.08307867  0.16291389 -0.20054172 -0.09870676\n",
      "  0.00395314 -0.02411225  0.12558883  0.01361088 -0.0078366   0.04378446\n",
      " -0.09386313 -0.31746897 -0.11640804 -0.04612681  0.02212676 -0.01935682\n",
      " -0.0547578   0.03608106 -0.19530745 -0.04637183  0.01912687  0.11497663\n",
      " -0.00105385 -0.04235512  0.11792496  0.00358367 -0.16271603  0.01034343\n",
      "  0.03794101  0.28001353  0.23270431  0.06507163  0.02541006 -0.1191501\n",
      "  0.10925017 -0.19054912  0.00961584  0.11663334  0.07023424  0.05479865\n",
      " -0.04299174 -0.15771416  0.02530648  0.08325924 -0.15095571  0.03554591\n",
      "  0.08526956 -0.1296019  -0.03462535 -0.08165399  0.28628907  0.06441644\n",
      " -0.1774088  -0.17032814  0.1208156  -0.20205812 -0.07136375  0.02304522\n",
      " -0.15062198 -0.15138213 -0.37378144  0.01976718  0.37277848  0.13110307\n",
      " -0.17048238  0.05170492 -0.05419494  0.05882671  0.16524723  0.15588589\n",
      " -0.01588624  0.03763153 -0.11986803  0.00273215  0.24760117 -0.07846\n",
      " -0.08623724  0.23065871 -0.0213409   0.11565614  0.0325521   0.05310603\n",
      " -0.05656437 -0.01341127 -0.10960821  0.02434343  0.03997903 -0.08477365\n",
      "  0.0039455   0.14284514 -0.09564464  0.11971255 -0.02280726  0.07825869\n",
      "  0.00039189 -0.04951854 -0.16641094 -0.06417198  0.14921631 -0.22589712\n",
      "  0.22687213  0.19561519  0.08402264  0.12235253  0.1496803   0.08411311\n",
      " -0.03185561 -0.01536986 -0.17812869 -0.02877955  0.07657135 -0.04613458\n",
      "  0.13339631 -0.0006706 ]\n",
      "0.39999999999999997\n"
     ]
    }
   ],
   "source": [
    "path_to_test = '/home/lee/dataset/CK+/test_images/9.jpg'\n",
    "unknown_face = face_recognition.load_image_file(path_to_test)\n",
    "unknown_face_encoding = face_recognition.face_encodings(unknown_face)[0]\n",
    "\n",
    "result = []\n",
    "offset = 0.05\n",
    "start = 0.35\n",
    "stop = 0.65\n",
    "tolerance = 0.35\n",
    "while(len(result) == 0 and tolerance < stop):\n",
    "    compare_results = face_recognition.compare_faces(known_faces, unknown_face_encoding, tolerance) \n",
    "    tolerance += offset\n",
    "    for i in range(0, len(compare_results)):\n",
    "        if(compare_results[i] == True):\n",
    "            if(subject_images[i][1] not in result):\n",
    "                result.append(subject_images[i][1])\n",
    "\n",
    "print(result)\n",
    "print(unknown_face_encoding)\n",
    "print(tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True]\n",
      "[-0.10575922  0.09650114 -0.0073488  -0.06721263 -0.08826589 -0.04560251\n",
      " -0.08840216 -0.13951473  0.10377172 -0.10629282  0.19541229 -0.04173768\n",
      " -0.23411161 -0.0978996  -0.08307867  0.16291389 -0.20054172 -0.09870676\n",
      "  0.00395314 -0.02411225  0.12558883  0.01361088 -0.0078366   0.04378446\n",
      " -0.09386313 -0.31746897 -0.11640804 -0.04612681  0.02212676 -0.01935682\n",
      " -0.0547578   0.03608106 -0.19530745 -0.04637183  0.01912687  0.11497663\n",
      " -0.00105385 -0.04235512  0.11792496  0.00358367 -0.16271603  0.01034343\n",
      "  0.03794101  0.28001353  0.23270431  0.06507163  0.02541006 -0.1191501\n",
      "  0.10925017 -0.19054912  0.00961584  0.11663334  0.07023424  0.05479865\n",
      " -0.04299174 -0.15771416  0.02530648  0.08325924 -0.15095571  0.03554591\n",
      "  0.08526956 -0.1296019  -0.03462535 -0.08165399  0.28628907  0.06441644\n",
      " -0.1774088  -0.17032814  0.1208156  -0.20205812 -0.07136375  0.02304522\n",
      " -0.15062198 -0.15138213 -0.37378144  0.01976718  0.37277848  0.13110307\n",
      " -0.17048238  0.05170492 -0.05419494  0.05882671  0.16524723  0.15588589\n",
      " -0.01588624  0.03763153 -0.11986803  0.00273215  0.24760117 -0.07846\n",
      " -0.08623724  0.23065871 -0.0213409   0.11565614  0.0325521   0.05310603\n",
      " -0.05656437 -0.01341127 -0.10960821  0.02434343  0.03997903 -0.08477365\n",
      "  0.0039455   0.14284514 -0.09564464  0.11971255 -0.02280726  0.07825869\n",
      "  0.00039189 -0.04951854 -0.16641094 -0.06417198  0.14921631 -0.22589712\n",
      "  0.22687213  0.19561519  0.08402264  0.12235253  0.1496803   0.08411311\n",
      " -0.03185561 -0.01536986 -0.17812869 -0.02877955  0.07657135 -0.04613458\n",
      "  0.13339631 -0.0006706 ]\n",
      "[0.35733736]\n",
      "0.3700000000000002\n"
     ]
    }
   ],
   "source": [
    "path_to_test1 = '/home/lee/dataset/CK+/test_images/32.jpg'\n",
    "path_to_test2 = '/home/lee/dataset/CK+/test_images/9.jpg'\n",
    "\n",
    "unknown_face1 = face_recognition.load_image_file(path_to_test1)\n",
    "unknown_face_encoding1 = face_recognition.face_encodings(unknown_face1)[0]\n",
    "\n",
    "unknown_face2 = face_recognition.load_image_file(path_to_test2)\n",
    "unknown_face_encoding2 = face_recognition.face_encodings(unknown_face2)[0]\n",
    "known_face_tmp = []\n",
    "known_face_tmp.append(unknown_face_encoding1)\n",
    "\n",
    "result = []\n",
    "offset = 0.01\n",
    "start = 0.35\n",
    "stop = 0.65\n",
    "tolerance = 0.1\n",
    "compare_results = [False]\n",
    "while(compare_results[0] == False and tolerance < stop):\n",
    "    compare_results = face_recognition.compare_faces(known_face_tmp, unknown_face_encoding2, tolerance) \n",
    "    tolerance += offset\n",
    "    \n",
    "print(compare_results)\n",
    "print(unknown_face_encoding2)\n",
    "print(face_recognition.face_distance(known_face_tmp, unknown_face_encoding2known_face_tmp, unknown_face_encoding2))\n",
    "print(tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "#save model\n",
    "# save_object(models, 'models/au_models.pkl')\n",
    "#save_object(facs, '/Programing/GR/Code/Python/models/facs.pkl')\n",
    "# save_object(clf, 'models/emotion_model.pkl')\n",
    "# save_object(x_training + x_testing, 'models/normalize_data.pkl')\n",
    "save_object(subject_images, 'models/subject_images.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
