{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1034 assets, index the returned LazyList to import.\n",
      "Found 152 assets, index the returned LazyList to import.\n"
     ]
    }
   ],
   "source": [
    "#svm\n",
    "import menpo.io as mio\n",
    "import os\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "import math\n",
    "import Models\n",
    "from Models import ChangeVector, ImageData\n",
    "path_to_svm_training_database = '/Programing/GR/Code/CK+/aam-images/**/**/**/*'\n",
    "import pickle\n",
    "\n",
    "\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def process(image, crop_proportion=0.2, max_diagonal=400):\n",
    "    if image.n_channels == 3:\n",
    "        image = image.as_greyscale()\n",
    "    image = image.crop_to_landmarks_proportion(crop_proportion)\n",
    "    d = image.diagonal()\n",
    "    if d > max_diagonal:\n",
    "        image = image.rescale(float(max_diagonal) / d)\n",
    "    return image\n",
    "\n",
    "#process changingVector, reduce dimension from 2x68 to 1x68, by process PCA\n",
    "def pca(changeVector):\n",
    "    X = np.array(changeVector)\n",
    "    pca_model = PCA(n_components=1)\n",
    "    return pca_model.fit_transform(X)\n",
    "\n",
    "#chuan hoa theo max tung landmark\n",
    "def landmark_normalize(landmark):\n",
    "    vector_max = 0\n",
    "    for p in landmark:\n",
    "        if(math.sqrt(float(p[0])*float(p[0]) + float(p[1])*float(p[1])) > vector_max):\n",
    "            vector_max = math.sqrt(p[0]*p[0] + p[1]*p[1])\n",
    "    for p in landmark:\n",
    "        p[0] = p[0]/float(vector_max)\n",
    "        p[1] = p[1]/float(vector_max)\n",
    "    return landmark\n",
    "\n",
    "#chuan hoa mang 68 diem landmark cua perk state theo neutral state\n",
    "def normalize_perk_landmark(landmark_perk, landmark_neutral):\n",
    "    neutral_center = landmark_neutral[30]\n",
    "    perk_center = landmark_perk[30]\n",
    "#     for lm in landmark_perk:\n",
    "    #move perk landmark to match center of neutral landmark\n",
    "    move_vector = [neutral_center[0] - perk_center[0], neutral_center[1] - perk_center[1]]\n",
    "    for lm in landmark_perk:\n",
    "        lm[0] += move_vector[0]\n",
    "        lm[1] += move_vector[1]\n",
    "    \n",
    "    #scale the size of detected perk landmark based on neutrol landmark 27 to 30 (the nose)\n",
    "    scale_neutral = [landmark_neutral[30][0] - landmark_neutral[27][0], landmark_neutral[30][1] - landmark_neutral[27][1]]\n",
    "    scale_perk = [landmark_perk[30][0] - landmark_perk[27][0], landmark_perk[30][1] - landmark_perk[27][1]]\n",
    "    ratio = math.sqrt(scale_neutral[0]*scale_neutral[0] + scale_neutral[1]*scale_neutral[1])/math.sqrt(scale_perk[0]*scale_perk[0]+scale_perk[1]*scale_perk[1]) \n",
    "    for lm in landmark_perk:\n",
    "        lm[0] = (perk_center[0] - lm[0]) * (1 - ratio) + lm[0]\n",
    "        lm[1] = (perk_center[1] - lm[1]) * (1 - ratio) + lm[1]\n",
    "        \n",
    "    return landmark_perk\n",
    "\n",
    "#import images\n",
    "training_images = mio.import_images(path_to_svm_training_database, verbose=True)\n",
    "training_images = training_images.map(process)\n",
    "\n",
    "path_to_facs = '/Programing/GR/Code/CK+/FACS/'\n",
    "path_to_emotions = '/Programing/GR/Code/CK+/Emotion/'\n",
    "\n",
    "#create training data\n",
    "\n",
    "#check if example is labeled\n",
    "labeled_subject = []\n",
    "emotion_subject = os.listdir(path_to_emotions)\n",
    "for subject in emotion_subject:\n",
    "    session = os.listdir(path_to_emotions + \"/\" + subject)\n",
    "    for s in session:\n",
    "        labeled_subject.append(subject + \"-\" + s)\n",
    "\n",
    "count = 0;\n",
    "svm_training_data = []\n",
    "while(count < len(training_images)):\n",
    "    file_path = str(training_images[count].path).split(\"\\\\\")\n",
    "    facs_path = path_to_facs + file_path[6] + '/' + file_path[7]\n",
    "    gt_emotion = -1\n",
    "    \n",
    "    #get emotion label from Emotion Folder\n",
    "    emotion_checker = file_path[6] + \"-\" + file_path[7]\n",
    "    if(emotion_checker in  labeled_subject):\n",
    "        emotion_path = path_to_emotions + file_path[6] + '/' + file_path[7]\n",
    "        if(len(os.listdir(emotion_path)) != 0):\n",
    "            emotion_path = emotion_path + '/' + os.listdir(emotion_path)[0]\n",
    "            fi = open(emotion_path)\n",
    "            for line in fi:\n",
    "                if(line.split()):\n",
    "                    gt_emotion = int(float(line.split()[0]))\n",
    "#                 print(emotion_path + \":\" + str(gt_emotion))\n",
    "            fi.close()\n",
    "    \n",
    "    #get facs from FACS folder\n",
    "    facs_path = facs_path + '/' + os.listdir(facs_path)[0]\n",
    "    fi = open(facs_path, 'r')\n",
    "    data_facs = {}\n",
    "    tmp = []\n",
    "    for line in fi: # read rest of lines\n",
    "        if(line.split()):\n",
    "            tmp.append(line.split())\n",
    "    for f in tmp:\n",
    "        data_facs[str(int(float(f[0])))] = int(float(f[1]))\n",
    "    fi.close()\n",
    "    \n",
    "    landmark = []\n",
    "    landmark_neutral = training_images[count].landmarks['PTS'].lms.points\n",
    "    landmark_perk = training_images[count + 1].landmarks['PTS'].lms.points\n",
    "    for i in range(0,68):\n",
    "        landmark.append([landmark_perk[i][0] - landmark_neutral[i][0], landmark_perk[i][1] - landmark_neutral[i][1]])\n",
    "\n",
    "#     svm_training_data.append(ChangeVector(data_facs, landmarkChange, gt_emotion))   \n",
    "\n",
    "    svm_training_data.append(ImageData(data_facs, landmark, gt_emotion))\n",
    "    count = count + 2\n",
    "    \n",
    "\n",
    "facs = []\n",
    "#create facs array\n",
    "for data in svm_training_data:\n",
    "    for facs_code in data.facs:\n",
    "        if((int(facs_code)) not in facs):\n",
    "            facs.append(int(facs_code))\n",
    "facs.sort()\n",
    "\n",
    "#create testing data\n",
    "svm_testing_data = []\n",
    "path_to_svm_testing_database = \"/Programing/GR/Code/CK+/test-aam-images/**/**/**/*\"\n",
    "testing_images = mio.import_images(path_to_svm_testing_database, verbose=True)\n",
    "testing_images = testing_images.map(process)\n",
    "\n",
    "count = 0;\n",
    "while(count < len(testing_images)):\n",
    "    file_path = str(testing_images[count].path).split(\"\\\\\")\n",
    "#     print(file_path)\n",
    "    facs_path = path_to_facs + file_path[6] + '/' + file_path[7]\n",
    "    gt_emotion = -1\n",
    "    \n",
    "    #get emotion label from Emotion Folder\n",
    "    emotion_checker = file_path[6] + \"-\" + file_path[7]\n",
    "    if(emotion_checker in  labeled_subject):\n",
    "        emotion_path = path_to_emotions + file_path[6] + '/' + file_path[7]\n",
    "        if(len(os.listdir(emotion_path)) != 0):\n",
    "            emotion_path = emotion_path + '/' + os.listdir(emotion_path)[0]\n",
    "            fi = open(emotion_path)\n",
    "            for line in fi:\n",
    "                if(line.split()):\n",
    "                    gt_emotion = int(float(line.split()[0]))\n",
    "#                 print(emotion_path + \":\" + str(gt_emotion))\n",
    "            fi.close()\n",
    "    \n",
    "    \n",
    "    #get facs from FACS folder\n",
    "    facs_path = facs_path + '/' + os.listdir(facs_path)[0]\n",
    "    fi = open(facs_path, 'r')\n",
    "    data_facs = {}\n",
    "    tmp = []\n",
    "    for line in fi: # read rest of lines\n",
    "        if(line.split()):\n",
    "            tmp.append(line.split())\n",
    "    for f in tmp:\n",
    "        data_facs[str(int(float(f[0])))] = int(float(f[1]))\n",
    "    fi.close()\n",
    "    \n",
    "    landmark = []\n",
    "    landmark_neutral = testing_images[count].landmarks['PTS'].lms.points\n",
    "    landmark_perk = testing_images[count + 1].landmarks['PTS'].lms.points\n",
    "    landmark_perk = normalize_perk_landmark(landmark_neutral, landmark_perk)\n",
    "    for i in range(0,68):\n",
    "        landmark.append([landmark_perk[i][0] - landmark_neutral[i][0], landmark_perk[i][1] - landmark_neutral[i][1]])\n",
    "    \n",
    "#     svm_testing_data.append(ChangeVector(data_facs, landmarkChange, gt_emotion))   \n",
    "    svm_testing_data.append(ImageData(data_facs, landmark, gt_emotion))\n",
    "    count = count + 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.65925254068609\n",
      "10.685911471229382\n",
      "-3.3151721815999693\n",
      "1.9078923144025737\n",
      "-2.722642940762043\n",
      "-1.700653402429765\n",
      "0.3651190793203867\n",
      "-2.7312248247726103\n",
      "2.4754409177349075\n",
      "0.09280751860708847\n",
      "-5.658756900391168\n",
      "2.007511321660047\n",
      "-1.9663663765899386\n",
      "-1.0211952609605675\n",
      "-2.33264650472681\n",
      "0.9619512099257577\n",
      "-0.9253056661937293\n",
      "-4.881290655989183\n",
      "-9.623165929481814\n",
      "-1.7208034054260253\n",
      "-2.170710263302631\n",
      "-1.8138835488784082\n",
      "0.009958898028763485\n",
      "-0.3220725258433177\n",
      "0.32914676459687087\n",
      "-16.91036117175546\n",
      "1.3652444319720374\n",
      "4.520186034358709\n",
      "-1.6556728238670644\n",
      "2.2733032472095545\n",
      "1.28770679344413\n",
      "-0.06587010020245287\n",
      "-2.6127380850896103\n",
      "-0.17044171541046893\n",
      "-3.459752560916911\n",
      "0.6722025539457377\n",
      "1.9178482745328154\n",
      "-0.9114190752221418\n",
      "-4.060658715615958\n",
      "2.444975473636063\n",
      "0.31684516701292154\n",
      "2.1149800110679564\n",
      "0.5220659061639594\n",
      "-13.915702546852515\n",
      "-2.0988977959369493\n",
      "-5.485932419374016\n",
      "-2.1050285179206156\n",
      "-4.770028326543866\n",
      "-1.7283575623750025\n",
      "-10.89199931310118\n",
      "-0.6315214537619909\n",
      "-4.850833016812821\n",
      "0.01406920102013487\n",
      "0.8631336521105553\n",
      "1.3821844628146067\n",
      "-1.694872202876752\n",
      "-3.656079270045062\n",
      "3.6747041128439974\n",
      "0.5032699136672889\n",
      "-1.3579831966055025\n",
      "1.2924907506466283\n",
      "2.319558352287629\n",
      "-10.31396009517266\n",
      "-4.2930053218909165\n",
      "1.912547203351707\n",
      "0.37552745284691014\n",
      "-2.467964638443135\n",
      "-6.296976473166886\n",
      "-1.9136890531732504\n",
      "1.0673980232826636\n",
      "0.0005605124767740222\n",
      "0.3748939823791346\n",
      "0.0011060678081449282\n",
      "-2.264136363207058\n",
      "11.222196345941967\n",
      "0.18541424630925007\n",
      "-1.4334345228751744\n",
      "-4.675802159032919\n",
      "-3.3507384220488987\n",
      "-6.1447656320306905\n",
      "0.052918361613670584\n",
      "-3.455025786912117\n",
      "0.4728724851358521\n",
      "-7.361005065322978\n",
      "2.7924218084934296\n",
      "-0.5588121732350544\n",
      "0.8301601829203875\n",
      "-3.413089381297077\n",
      "-10.087803209226948\n",
      "0.6503024634301795\n",
      "1.7332614157328194\n",
      "-2.1941080182328676\n",
      "-7.953337931661004\n",
      "5.276478764824347\n",
      "1.2411657163051188\n",
      "-8.837867691847585\n",
      "1.2124183071064678\n",
      "-0.7326207796190545\n",
      "-0.3319697581971539\n",
      "-3.4118653826422403\n",
      "-1.5256991711496468\n",
      "-0.24619668053872346\n",
      "2.154001379223139\n",
      "-1.8428556738218518\n",
      "-8.500974580144636\n",
      "0.566543409974507\n",
      "1.0851657864099167\n",
      "-3.8386990039277578\n",
      "0.16085344068245178\n",
      "-2.616279366811206\n",
      "-4.018959516930039\n",
      "0.3900998998666054\n",
      "0.8688187310047439\n",
      "1.6639861369694628\n",
      "5.11370401734041\n",
      "-0.8685463046204873\n",
      "-4.890629697167313\n",
      "4.3575943465197895\n",
      "-0.21116094603592472\n",
      "-2.6802454260546895\n",
      "0.17437070546355216\n",
      "0.0005762051554967229\n",
      "-0.10582358789415025\n",
      "0.5832205696659685\n",
      "-4.476107723831404\n",
      "-5.929804261380561\n",
      "-9.569290337374795\n",
      "-0.49961051365405496\n",
      "-2.7600236811725978\n",
      "-2.0940262995575054\n",
      "-1.17543163706015\n",
      "-10.883844981715711\n",
      "-0.012082412187851332\n",
      "-0.6238695207408753\n",
      "-1.547016191552892\n",
      "-1.2773858248752248\n",
      "0.05715350055706381\n",
      "-0.550884744973601\n",
      "-0.3315532838999431\n",
      "-0.0038355895567647735\n",
      "0.44845416084455536\n",
      "0.2555835344782338\n",
      "0.06874347311526208\n",
      "-0.36619513685817395\n",
      "-0.4386192788374288\n",
      "1.7403041336699872\n",
      "0.5421051550380511\n",
      "-0.5944365308788946\n",
      "0.9199910011000298\n",
      "-1.0629029040169584\n",
      "0.724915476637392\n",
      "-10.371490768193567\n",
      "-4.852278092449076\n",
      "-2.018786870176072\n",
      "0.5086790139023876\n",
      "-1.55402117552795\n",
      "-0.41583405114097616\n",
      "0.29254985276112677\n",
      "-5.075815964550699\n",
      "-5.404843673793295\n",
      "-0.42466024333223373\n",
      "-1.6487947574809851\n",
      "-1.9744486405287418\n",
      "-0.10969856485450435\n",
      "0.08425168656615512\n",
      "0.0661288381716858\n",
      "-1.0773529535994442\n",
      "1.159605320223065\n",
      "-9.180843670810134\n",
      "-1.5538190961513578\n",
      "0.029371894268066967\n",
      "0.05361919442317742\n",
      "-1.985280758045512\n",
      "-1.7506352570354409\n",
      "-3.6647267714959924\n",
      "0.5147298022454265\n",
      "-2.7972808885819163\n",
      "-1.3740495343059465\n",
      "3.467964283334254\n",
      "1.2863896464004014\n",
      "0.6647242393598631\n",
      "-0.0772167124955132\n",
      "-0.08135502943901685\n",
      "-0.14120698087545946\n",
      "0.07461969186834239\n",
      "-5.446358745896347\n",
      "-1.5707562602705991\n",
      "3.233707989224925\n",
      "2.3001356875536842\n",
      "-0.41422862507589286\n",
      "-19.57236213953189\n",
      "-8.302406206180457\n",
      "-8.067799916386676\n",
      "0.01691758203471494\n",
      "-15.722460442888192\n",
      "3.5706866173707468\n",
      "-0.23078193248547052\n",
      "-8.15262670692114\n",
      "-0.07653792540617843\n",
      "-2.5295946613495275\n",
      "-0.6223759130472715\n",
      "-2.7023331038711476\n",
      "1.001578781871082\n",
      "-0.09997287346323702\n",
      "-5.791146660829021\n",
      "-6.501593594842056\n",
      "4.101728984058212\n",
      "3.244922178825611\n",
      "-0.6102612616385059\n",
      "-6.243910870263207\n",
      "-0.2451366887018338\n",
      "-1.78978399454585\n",
      "0.12903810624028011\n",
      "0.628891178931184\n",
      "-6.278010321646384\n",
      "-3.0854192853731135\n",
      "0.3557691399806444\n",
      "0.12974293648739632\n",
      "-0.6643677957666867\n",
      "-0.11382755868140748\n",
      "0.017916884270896105\n",
      "-1.2188152909244536\n",
      "-3.434038024767162\n",
      "0.5979561826439266\n",
      "4.152051114033036\n",
      "0.4437917774878315\n",
      "0.11580841663693775\n",
      "0.011685689545750222\n",
      "-0.36920629066910493\n",
      "-1.147479662545372\n",
      "0.6291645700182684\n",
      "-0.208115448057967\n",
      "2.352367553773533\n",
      "-4.155362570811931\n",
      "-1.776339208939433\n",
      "-1.378094898818496\n",
      "2.9868206611268917\n",
      "-6.873300066316581\n",
      "-0.8270354088360321\n",
      "-2.7993383544445365\n",
      "7.483429158129091\n",
      "0.4425384565149173\n",
      "-0.14442209070928413\n",
      "-0.22206658830105397\n",
      "-0.347667611671028\n",
      "1.3274139298733303\n",
      "0.20172480980375695\n",
      "-1.5666459897849663\n",
      "2.412835142198915\n",
      "-2.1573968044180276\n",
      "-0.3066125299718223\n",
      "-5.837453104793411\n",
      "-2.4186244928300695\n",
      "-7.402108971695945\n",
      "-5.467224359366462\n",
      "-0.45469927098016427\n",
      "1.5229766453110116\n",
      "-8.975894118717974\n",
      "-2.8986062970949504\n",
      "5.503652629002488\n",
      "3.870796237774414\n",
      "1.0697098990025609\n",
      "-2.826031503768462\n",
      "0.08431828833626298\n",
      "-6.176927811296714\n",
      "-3.7144830657194774\n",
      "0.057281169654473274\n",
      "-0.0025016111115476747\n",
      "-2.2560894882217326\n",
      "-0.7923551141832732\n",
      "0.8999783199480618\n",
      "-0.7768301173755745\n",
      "-1.5722516213695172\n",
      "0.318406234518676\n",
      "0.059954535812195786\n",
      "0.014426377650146094\n",
      "-0.465582389029791\n",
      "0.3926762778541786\n",
      "-0.2662673268539777\n",
      "-0.002159041621766278\n",
      "0.5345453724652458\n",
      "-0.07853212513693819\n",
      "0.16286039074914527\n",
      "-0.06764103115013143\n",
      "0.37038148883949873\n",
      "-0.0015263879920723866\n",
      "-0.3703255546334816\n",
      "-3.802209139853737\n",
      "0.8161022651593584\n",
      "-5.0994081550913535\n",
      "1.6784075785768096\n",
      "-4.049057131916754\n",
      "1.0807653824975958\n",
      "4.226665562249806\n",
      "0.800631203872932\n",
      "1.8737250273382742\n",
      "-5.16317293100893\n",
      "-7.351901808411853\n",
      "-5.859747803636559\n",
      "4.602202748418897\n",
      "4.7852997675900255\n",
      "0.4541206699501359\n",
      "0.8386501075477355\n",
      "-0.38224976516725917\n",
      "-4.079663749091559\n",
      "4.143219727456952\n",
      "-0.14221560759776963\n",
      "3.450772334643169\n",
      "-0.5966406294041491\n",
      "0.08994176355115258\n",
      "-0.48493707140225695\n",
      "-3.4867562355934396\n",
      "-1.7363304328253903\n",
      "-3.0047880573893337\n",
      "-0.4510001672834747\n",
      "-7.106553273698644\n",
      "0.13872384056649878\n",
      "0.11142158333840513\n",
      "1.802814490735507\n",
      "-0.7672352235172468\n",
      "7.627180091925844\n",
      "0.2763992414330687\n",
      "-10.37513720610388\n",
      "0.2833379179687938\n",
      "-0.010171333272175787\n",
      "-1.5641907328421283\n",
      "-9.08634589045542\n",
      "0.8016479132393854\n",
      "-1.9321436052871448\n",
      "-1.7012046995835064\n",
      "-5.804532559707141\n",
      "0.24682127534328657\n",
      "0.27710220312440015\n",
      "6.390193796281679\n",
      "0.9769751803085356\n",
      "0.5556397625381848\n",
      "-2.476568641701064\n",
      "0.0815091981544569\n",
      "0.006334183384268499\n",
      "-0.1335208965278767\n",
      "-5.53661789952816\n",
      "-0.018845463838538024\n",
      "-3.4073298934100364\n",
      "-0.38586792976663986\n",
      "0.7478620776710443\n",
      "-0.32853024051512136\n",
      "-2.076902877631383\n",
      "-1.3579429472620888\n",
      "-3.035464969346627\n",
      "2.345645740749319\n",
      "3.047272389715495\n",
      "-0.4799583975769579\n",
      "0.057547941363175426\n",
      "-0.009827701544743661\n",
      "-0.4811186807084624\n",
      "0.0085153013975372\n",
      "-8.730123814362805\n",
      "0.007973275383669431\n",
      "-0.004504649064216437\n",
      "-0.538226192991786\n",
      "-0.3999966327429192\n",
      "1.3909094431781739\n",
      "-1.0511242357537895\n",
      "-3.7362806616049156\n",
      "-1.5038623369286555\n",
      "1.6041977002923602\n",
      "0.44892267940323194\n",
      "-1.11462660633606\n",
      "2.367794639690409\n",
      "0.0011921304173867497\n",
      "2.3429311807685806\n",
      "0.09430005118893803\n",
      "-0.06953000327597891\n",
      "0.15501485646952062\n",
      "-0.0438668395210442\n",
      "-6.803765737834432\n",
      "-2.02260184171098\n",
      "2.0786011795316597\n",
      "-0.5095576860443956\n",
      "-1.8017194240943297\n",
      "0.09292767905539989\n",
      "-0.2576738371341136\n",
      "-2.188979182568886\n",
      "5.31593070374705\n",
      "-0.5595042748733121\n",
      "-2.502738488212607\n",
      "0.3297830482943098\n",
      "-1.298447718090621\n",
      "-0.43555431740357875\n",
      "-0.23978521912147244\n",
      "-1.1305459466528447\n",
      "-3.603678185134328\n",
      "4.7433787411234505\n",
      "3.790199297548199\n",
      "-0.8743707743434257\n",
      "-7.422741298048656\n",
      "0.10042947693960969\n",
      "3.4868825301684936\n",
      "0.06619566678421052\n",
      "-1.6730071774142061\n",
      "-7.122409830589618\n",
      "-3.0916890873438376\n",
      "1.572515006313651\n",
      "0.23389758851077147\n",
      "0.45749353631494927\n",
      "-1.9435072267446714\n",
      "-0.042088788116181775\n",
      "-0.5200959951669688\n",
      "-7.706070194197068\n",
      "-1.167305011742485\n",
      "-2.241694559807293\n",
      "1.4161511595730332\n",
      "-5.236133226557904\n",
      "2.9892079558896683\n",
      "-3.1623530290137936\n",
      "0.30247524199459974\n",
      "0.015897349639175218\n",
      "-1.058631764356619\n",
      "1.825164529976334\n",
      "0.3117562622191059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007536763339473396\n",
      "1.43437894837475\n",
      "1.1142056872896973\n",
      "0.8831305844241442\n",
      "-1.1846803139534927\n",
      "2.718831944412713\n",
      "0.007986211070630134\n",
      "0.3202008661018496\n",
      "-0.061665920289158294\n",
      "-0.11508811567708932\n",
      "0.16928089946193126\n",
      "-1.5415452918219827\n",
      "5.515578233898665\n",
      "0.2841657036706877\n",
      "-8.785602850176645\n",
      "-0.006575287022315024\n",
      "0.12262225552269967\n",
      "1.5800087243804057\n",
      "-0.8023131055319297\n",
      "-0.4026191167285802\n",
      "-3.8284436115757643\n",
      "-0.2747120715048297\n",
      "1.2743067609198278\n",
      "0.9654791577735011\n",
      "0.008216470505345796\n",
      "-7.592446458641952\n",
      "4.562756264123934\n",
      "1.9319374888661187\n",
      "-0.5939780253632492\n",
      "-5.906690483357082\n",
      "2.187339465352345\n",
      "3.257710339031277\n",
      "-1.7605012026174762\n",
      "0.0001072210301131804\n",
      "-0.121509843194751\n",
      "6.006921739146875\n",
      "-1.5099862644713369\n",
      "-3.9498827040671003\n",
      "0.3463274281272035\n",
      "-1.9234395359011032\n",
      "-3.848787340853633\n",
      "-1.4929701254090872\n",
      "-1.3875841853548962\n",
      "2.7166154386954773\n",
      "-0.3803332256239429\n",
      "-1.3052132725106205\n",
      "-0.4651734662041065\n",
      "-0.5278799563207173\n",
      "-2.428046037697868\n",
      "-2.0566274134972815\n",
      "-0.08878658357412661\n",
      "-0.45867534782901487\n",
      "-2.4697251537403133\n",
      "1.6984290396029564\n",
      "-0.0038247996658640204\n",
      "-2.7726359767313795\n",
      "0.5018793562238812\n",
      "-1.074659201061749\n",
      "0.5738112948742753\n",
      "4.892145232585946\n",
      "2.0236733880234468\n",
      "2.9690121825158187\n",
      "8.35478391360018\n",
      "-1.198981013775807\n",
      "0.28963165851681794\n",
      "-0.20538242106456295\n",
      "-0.625800724928574\n",
      "-0.06473727121139206\n",
      "-0.4715065090038095\n",
      "0.23811271155731362\n",
      "0.2532264478176245\n",
      "0.4486460049969452\n",
      "0.09634516635685486\n",
      "0.3538671001750089\n",
      "-0.8398505838462924\n",
      "3.1349202443712585\n",
      "-1.0032705094202399\n",
      "0.47376444838225495\n",
      "1.1549608616100784\n",
      "2.319355529112819\n",
      "-2.4681952573178663\n",
      "-0.08461114735076336\n",
      "0.0018980724623389733\n",
      "1.6428565992372413\n",
      "-4.0031551516285475\n",
      "-0.4375684045077577\n",
      "2.8773972444096074\n",
      "-0.63113530079508\n",
      "2.6724149459024957\n",
      "2.6397198655383747\n",
      "2.6766105576039934\n",
      "1.407646721068403\n",
      "-3.1498942878007483\n",
      "2.289442682771444\n",
      "-0.11901840193051783\n",
      "-0.4041614669193123\n",
      "0.9758847406590903\n"
     ]
    }
   ],
   "source": [
    "#normalize perk landmark according to neutral landmark position\n",
    "def mean_landmark_point(landmark):\n",
    "    x_mean = 0\n",
    "    y_mean = 0\n",
    "    for lm in landmark:\n",
    "        x_mean += lm[0]\n",
    "        y_mean += lm[1]\n",
    "    return [x_mean/68, y_mean/68]\n",
    "\n",
    "def normalize_perk_landmark(landmark_perk, landmark_neutral):\n",
    "    neutral_center = mean_landmark_point(landmark_neutral)\n",
    "    perk_center = mean_landmark_point(landmark_perk)\n",
    "#     for lm in landmark_perk:\n",
    "    #move perk landmark to match center of neutral landmark\n",
    "    move_vector = [neutral_center[0] - perk_center[0], neutral_center[1] - perk_center[1]]\n",
    "    for lm in landmark_perk:\n",
    "        lm[0] += move_vector[0]\n",
    "        lm[1] += move_vector[1]\n",
    "    \n",
    "    #scale the size of detected perk landmark based on neutrol landmark 27 to 30 (the nose)\n",
    "    scale_neutral = [landmark_neutral[30][0] - landmark_neutral[27][0], landmark_neutral[30][1] - landmark_neutral[27][1]]\n",
    "    scale_perk = [landmark_perk[30][0] - landmark_perk[27][0], landmark_perk[30][1] - landmark_perk[27][1]]\n",
    "    ratio = math.sqrt(scale_neutral[0]*scale_neutral[0] + scale_neutral[1]*scale_neutral[1])/math.sqrt(scale_perk[0]*scale_perk[0]+scale_perk[1]*scale_perk[1])    \n",
    "    for lm in landmark_perk:\n",
    "        lm[0] = (perk_center[0] - lm[0]) * (1 - ratio) + lm[0]\n",
    "        lm[1] = (perk_center[1] - lm[1]) * (1 - ratio) + lm[1]\n",
    "        \n",
    "    return landmark_perk\n",
    "\n",
    "count = 0\n",
    "while(count < len(training_images)):\n",
    "    landmark_neutral = training_images[count].landmarks['PTS'].lms.points\n",
    "    landmark_perk = training_images[count + 1].landmarks['PTS'].lms.points\n",
    "#     print([mean_landmark_point(landmark_neutral), mean_landmark_point(landmark_perk)])\n",
    "#     x = mean_landmark_point(landmark_perk)[0] -mean_landmark_point(landmark_neutral)[0]\n",
    "#     y = mean_landmark_point(landmark_perk)[1] -mean_landmark_point(landmark_neutral)[1]\n",
    "#     print(math.sqrt(x*x + y*y))\n",
    "    \n",
    "    x1 = landmark_perk[30][0] - landmark_perk[27][0]\n",
    "    y1 = landmark_perk[30][1] - landmark_perk[27][1]\n",
    "    x2 = landmark_neutral[30][0] - landmark_neutral[27][0]\n",
    "    y2 = landmark_neutral[30][1] - landmark_neutral[27][1]\n",
    "#     print(math.sqrt(x1*x1+y1*y1) - math.sqrt(x2*x2+y2*y2))\n",
    "    count += 2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  59.52933  128.8375 ]\n",
      "[  74.78126  129.00418]\n",
      "[  90.04854  128.82576]\n",
      "[ 105.07997  129.17517]\n",
      "[-0.6835399999999936, 1.6617200000000025]\n",
      "[ 104.39643  130.83689]\n",
      "[ 104.39643  130.83689]\n",
      "scale_neutral:[34.865980000000008, -0.0026000000000294676]\n",
      "scale_perk:[45.550640000000016, 0.3376700000000028]\n",
      "0.7654123439586024\n",
      "--\n",
      "[  69.53140787  130.57843321]\n",
      "[  81.20542336  130.70601214]\n",
      "[  92.89118793  130.56944727]\n",
      "[ 104.39643  130.83689]\n"
     ]
    }
   ],
   "source": [
    "#test normalize perk state\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def normalize_perk_landmark(landmark_perk, landmark_neutral):\n",
    "    neutral_center = landmark_neutral[30]\n",
    "    perk_center = landmark_perk[30]\n",
    "#     for lm in landmark_perk:\n",
    "    #move perk landmark to match center of neutral landmark\n",
    "    move_vector = [neutral_center[0] - perk_center[0], neutral_center[1] - perk_center[1]]\n",
    "    print(move_vector)\n",
    "    for lm in landmark_perk:\n",
    "        lm[0] += move_vector[0]\n",
    "        lm[1] += move_vector[1]\n",
    "    \n",
    "    print(landmark_neutral[30])\n",
    "    print(landmark_perk[30])\n",
    "    #scale the size of detected perk landmark based on neutrol landmark 27 to 30 (the nose)\n",
    "    scale_neutral = [landmark_neutral[30][0] - landmark_neutral[27][0], landmark_neutral[30][1] - landmark_neutral[27][1]]\n",
    "    scale_perk = [landmark_perk[30][0] - landmark_perk[27][0], landmark_perk[30][1] - landmark_perk[27][1]]\n",
    "    print(\"scale_neutral:\" + str(scale_neutral))\n",
    "    print(\"scale_perk:\" + str(scale_perk))\n",
    "    ratio = math.sqrt(scale_neutral[0]*scale_neutral[0] + scale_neutral[1]*scale_neutral[1])/math.sqrt(scale_perk[0]*scale_perk[0]+scale_perk[1]*scale_perk[1])    \n",
    "    print(ratio)\n",
    "    for lm in landmark_perk:\n",
    "        lm[0] = (perk_center[0] - lm[0]) * (1 - ratio) + lm[0]\n",
    "        lm[1] = (perk_center[1] - lm[1]) * (1 - ratio) + lm[1]\n",
    "        \n",
    "    return landmark_perk\n",
    "\n",
    "landmark_neutral = training_images[2].landmarks['PTS'].lms.points\n",
    "landmark_perk = training_images[3].landmarks['PTS'].lms.points\n",
    "\n",
    "for i in range (27,31):\n",
    "    print(landmark_perk[i])\n",
    "\n",
    "landmark_perk = normalize_perk_landmark(landmark_perk, landmark_neutral)\n",
    "\n",
    "print(\"--\")\n",
    "for i in range (27,31):\n",
    "    print(landmark_perk[i])\n",
    "# x = []\n",
    "# y = []\n",
    "# for i in range(0,68):\n",
    "#     x.append(training_images[0].landmarks['PTS'].lms.points[i][0])\n",
    "#     y.append(training_images[0].landmarks['PTS'].lms.points[i][1])\n",
    "# plt.plot(x,y, \"ro\")\n",
    "# plt.axis([0, 250, 0, 250])\n",
    "# plt.show()\n",
    "# for i in range (27,31):\n",
    "#     print(landmark_neutral[i])\n",
    "# print(\"--\")\n",
    "# for i in range (27,31):\n",
    "#     print(landmark_perk[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######\n",
      "Score: \n",
      "[0.89333333333333331, 0.92000000000000004, 0.78666666666666663, 0.77333333333333332, 0.81333333333333335, 0.81333333333333335, 0.97333333333333338, 0.94666666666666666, 0.82666666666666666, 0.90666666666666662, 1.0, 0.90666666666666662, 0.81333333333333335, 0.93333333333333335, 0.89333333333333331, 0.97333333333333338, 0.77333333333333332, 0.98666666666666669, 0.94666666666666666, 0.95999999999999996, 0.90666666666666662, 0.95999999999999996, 0.97333333333333338, 0.93333333333333335, 1.0, 1.0, 1.0, 1.0, 0.94666666666666666, 0.97333333333333338, 0.95999999999999996, 0.97333333333333338, 0.98666666666666669, 0.98666666666666669, 1.0, 1.0, 1.0, 1.0]\n",
      "0.932631578947\n"
     ]
    }
   ],
   "source": [
    "#create model for each action unit in facs[]\n",
    "models = []\n",
    "au_models_score = []\n",
    "for au in facs:\n",
    "    x_training = []\n",
    "    y_label = []\n",
    "    #create label array\n",
    "    for data in svm_training_data:\n",
    "        if(str(au) in data.facs):\n",
    "#             y_label.append(data.facs[str(au)])\n",
    "            y_label.append(1)\n",
    "        else:\n",
    "            y_label.append(-1)\n",
    "        #create training data: 1x68 array, result of PCA process\n",
    "        vector = []\n",
    "        for tmp in data.landmark:\n",
    "            vector.append(tmp[0])\n",
    "            vector.append(tmp[1])\n",
    "        x_training.append(vector)\n",
    "    clf = svm.SVC(kernel='linear', decision_function_shape = 'ovr')\n",
    "    clf.fit(normalize(x_training, norm='max', axis=0), y_label)\n",
    "    au_models_score.append(clf.score(normalize(x_training, norm='max', axis=0), y_label))\n",
    "    models.append(clf)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "#evaluate trained model with test data and get score\n",
    "print('#######')\n",
    "print('Score: ')\n",
    "au_test_score = []\n",
    "for au in facs:\n",
    "    x_training = []\n",
    "    y_label = []\n",
    "    #create label array\n",
    "    for data in svm_testing_data:\n",
    "        if(str(au) in data.facs):\n",
    "#             y_label.append(data.facs[str(au)])\n",
    "            y_label.append(1)\n",
    "        else:\n",
    "            y_label.append(-1)\n",
    "        #create training data: 1x68 array, result of PCA process\n",
    "        vector = []\n",
    "        for tmp in data.landmark:\n",
    "            vector.append(tmp[0])\n",
    "            vector.append(tmp[1])\n",
    "        x_training.append(vector)\n",
    "#     print(y_label)\n",
    "    au_test_score.append(models[facs.index(au)].score(normalize(x_training, norm='max', axis=0), y_label))\n",
    "print(au_test_score)\n",
    "print(np.mean(au_test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94953271028037378, 0.98691588785046724, 0.89719626168224298, 0.95327102803738317, 0.9196261682242991, 0.90467289719626165, 0.99252336448598133, 0.96635514018691593, 0.95140186915887848, 0.9738317757009346, 0.9981308411214953, 0.9719626168224299, 0.95514018691588787, 0.95887850467289715, 0.9476635514018692, 0.98691588785046724, 0.9719626168224299, 0.9981308411214953, 0.99439252336448603, 0.96635514018691593, 0.95514018691588787, 0.96635514018691593, 0.91588785046728971, 0.98878504672897194, 0.9981308411214953, 0.99626168224299061, 0.9981308411214953, 0.99626168224299061, 0.9981308411214953, 0.95514018691588787, 0.9738317757009346, 0.98504672897196266, 0.9981308411214953, 0.9719626168224299, 1.0, 0.9981308411214953, 0.99626168224299061, 0.99626168224299061, 0.99252336448598133]\n",
      "0.97244188833\n"
     ]
    }
   ],
   "source": [
    "print(au_models_score)\n",
    "print(np.mean(au_models_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "print(len(svm_testing_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####\n",
      "[[0, 1], [1, 1], [3, 1], [6, 1], [7, 1], [8, 1], [9, 1], [13, 1], [17, 1], [21, 1], [24, 1], [25, 1], [31, 1], [32, 1], [33, 1], [34, 1]]\n",
      "---\n",
      "{'14': 2, '24': 2, '12': 2}\n",
      "#####\n",
      "[[0, 1], [1, 1], [3, 1], [8, 1], [9, 1], [10, 1], [13, 1], [17, 1], [21, 1], [24, 1], [25, 1], [31, 1], [32, 1], [33, 1], [34, 1]]\n",
      "---\n",
      "{'14': 2, '12': 1}\n",
      "#####\n",
      "[[0, 1], [1, 1], [3, 1], [8, 1], [10, 1], [13, 1], [17, 1], [21, 1], [23, 1], [24, 1], [25, 1], [30, 1], [31, 1], [32, 1], [33, 1], [34, 1]]\n",
      "---\n",
      "{'14': 0}\n",
      "#####\n",
      "[[0, 1], [1, 1], [3, 1], [7, 1], [8, 1], [9, 1], [10, 1], [13, 1], [17, 1], [21, 1], [24, 1], [25, 1], [30, 1], [31, 1], [32, 1], [33, 1], [34, 1]]\n",
      "---\n",
      "{'14': 2, '12': 1}\n",
      "#####\n",
      "[[0, 1], [1, 1], [3, 1], [10, 1], [13, 1], [17, 1], [21, 1], [24, 1], [25, 1], [30, 1], [31, 1], [32, 1], [33, 1], [34, 1]]\n",
      "---\n",
      "{'14': 2, '17': 3}\n",
      "#####\n",
      "[[0, 1], [1, 1], [3, 1], [6, 1], [8, 1], [9, 1], [10, 1], [13, 1], [17, 1], [21, 1], [24, 1], [25, 1], [30, 1], [31, 1], [32, 1], [33, 1], [34, 1]]\n",
      "---\n",
      "{'14': 2, '17': 2, '12': 1}\n",
      "#####\n",
      "[[0, 1], [1, 1], [3, 1], [8, 1], [9, 1], [10, 1], [13, 1], [17, 1], [21, 1], [24, 1], [25, 1], [31, 1], [32, 1], [33, 1], [34, 1]]\n",
      "---\n",
      "{'15': 2, '23': 3, '4': 1, '2': 2, '17': 2, '1': 2}\n",
      "#####\n",
      "[[0, 1], [1, 1], [3, 1], [8, 1], [9, 1], [13, 1], [17, 1], [21, 1], [24, 1], [25, 1], [30, 1], [31, 1], [32, 1], [33, 1], [34, 1]]\n",
      "---\n",
      "{'15': 1, '23': 3, '5': 1, '17': 3, '4': 3}\n",
      "#####\n",
      "[[0, 1], [1, 1], [3, 1], [7, 1], [8, 1], [9, 1], [13, 1], [17, 1], [21, 1], [24, 1], [25, 1], [30, 1], [31, 1], [32, 1], [33, 1], [34, 1]]\n",
      "---\n",
      "{'14': 2, '26': 2, '20': 2, '4': 3, '5': 4, '25': 2, '17': 1, '1': 2}\n",
      "#####\n",
      "[[0, 1], [1, 1], [3, 1], [7, 1], [8, 1], [9, 1], [10, 1], [13, 1], [17, 1], [21, 1], [24, 1], [25, 1], [31, 1], [32, 1], [33, 1], [34, 1]]\n",
      "---\n",
      "{'15': 2, '17': 3, '1': 2, '4': 4}\n",
      "#####\n",
      "[[0, 1], [1, 1], [3, 1], [6, 1], [7, 1], [8, 1], [9, 1], [13, 1], [17, 1], [21, 1], [24, 1], [25, 1], [30, 1], [31, 1], [32, 1], [33, 1], [34, 1]]\n",
      "---\n",
      "{'23': 5, '5': 3, '38': 3, '17': 2, '4': 3}\n",
      "#####\n",
      "[[0, 1], [1, 1], [3, 1], [6, 1], [7, 1], [8, 1], [9, 1], [13, 1], [17, 1], [21, 1], [24, 1], [25, 1], [30, 1], [31, 1], [32, 1], [33, 1], [34, 1]]\n",
      "---\n",
      "{'14': 0}\n",
      "#####\n",
      "[[0, 1], [1, 1], [3, 1], [6, 1], [7, 1], [8, 1], [9, 1], [10, 1], [13, 1], [17, 1], [21, 1], [24, 1], [25, 1], [31, 1], [32, 1], [33, 1], [34, 1]]\n",
      "---\n",
      "{'14': 2, '20': 3, '4': 4, '38': 2, '5': 3, '25': 2, '16': 3, '1': 3}\n",
      "#####\n",
      "[[0, 1], [1, 1], [3, 1], [9, 1], [10, 1], [13, 1], [17, 1], [21, 1], [23, 1], [24, 1], [25, 1], [30, 1], [31, 1], [32, 1], [33, 1], [34, 1]]\n",
      "---\n",
      "{'23': 4, '5': 2, '38': 2, '17': 2, '4': 4}\n",
      "#####\n",
      "[[0, 1], [1, 1], [3, 1], [7, 1], [8, 1], [9, 1], [12, 1], [13, 1], [17, 1], [21, 1], [24, 1], [25, 1], [30, 1], [31, 1], [32, 1], [33, 1], [34, 1]]\n",
      "---\n",
      "{'14': 0}\n",
      "#####\n",
      "[[0, 1], [1, 1], [3, 1], [7, 1], [8, 1], [9, 1], [13, 1], [17, 1], [21, 1], [24, 1], [25, 1], [30, 1], [31, 1], [32, 1], [33, 1], [34, 1]]\n",
      "---\n",
      "{'15': 3, '17': 1, '4': 3}\n",
      "#####\n",
      "[[0, 1], [1, 1], [3, 1], [6, 1], [7, 1], [8, 1], [9, 1], [13, 1], [17, 1], [21, 1], [24, 1], [25, 1], [30, 1], [31, 1], [32, 1], [33, 1], [34, 1]]\n",
      "---\n",
      "{'15': 2, '30': 2, '9': 3, '4': 2, '23': 3, '5': 3, '17': 2}\n",
      "#####\n",
      "[[0, 1], [1, 1], [3, 1], [7, 1], [8, 1], [9, 1], [10, 1], [13, 1], [17, 1], [21, 1], [24, 1], [25, 1], [31, 1], [32, 1], [33, 1], [34, 1]]\n",
      "---\n",
      "{'14': 0}\n",
      "#####\n",
      "[[0, 1], [1, 1], [3, 1], [8, 1], [9, 1], [10, 1], [13, 1], [17, 1], [21, 1], [23, 1], [24, 1], [25, 1], [30, 1], [31, 1], [32, 1], [33, 1], [34, 1]]\n",
      "---\n",
      "{'14': 2, '26': 4, '20': 2, '4': 2, '2': 2, '5': 4, '25': 3, '17': 1, '1': 2}\n",
      "#####\n",
      "[[0, 1], [1, 1], [3, 1], [8, 1], [9, 1], [10, 1], [13, 1], [17, 1], [21, 1], [24, 1], [25, 1], [30, 1], [31, 1], [32, 1], [33, 1], [34, 1]]\n",
      "---\n",
      "{'2': 1, '15': 1, '17': 2, '1': 1, '4': 2}\n",
      "#####\n",
      "[[0, 1], [1, 1], [3, 1], [8, 1], [9, 1], [10, 1], [13, 1], [17, 1], [21, 1], [24, 1], [25, 1], [31, 1], [32, 1], [33, 1], [34, 1]]\n",
      "---\n",
      "{'14': 0}\n",
      "#####\n",
      "[[0, 1], [1, 1], [3, 1], [8, 1], [10, 1], [13, 1], [17, 1], [21, 1], [24, 1], [25, 1], [30, 1], [31, 1], [32, 1], [33, 1], [34, 1]]\n",
      "---\n",
      "{'15': 3, '38': 2, '17': 4, '1': 2, '4': 2}\n",
      "#####\n",
      "[[0, 1], [1, 1], [3, 1], [8, 1], [9, 1], [10, 1], [13, 1], [17, 1], [21, 1], [24, 1], [25, 1], [30, 1], [31, 1], [32, 1], [33, 1], [34, 1]]\n",
      "---\n",
      "{'23': 4, '5': 2, '6': 2, '7': 3, '17': 4}\n",
      "#####\n",
      "[[0, 1], [1, 1], [3, 1], [6, 1], [8, 1], [9, 1], [10, 1], [13, 1], [17, 1], [21, 1], [24, 1], [25, 1], [30, 1], [31, 1], [32, 1], [33, 1], [34, 1]]\n",
      "---\n",
      "{'14': 0}\n",
      "#####\n",
      "[[0, 1], [1, 1], [3, 1], [9, 1], [10, 1], [13, 1], [17, 1], [21, 1], [24, 1], [25, 1], [30, 1], [31, 1], [32, 1], [33, 1], [34, 1]]\n",
      "---\n",
      "{'20': 3, '4': 2, '2': 4, '5': 4, '25': 1, '1': 4}\n",
      "#####\n",
      "[[0, 1], [1, 1], [3, 1], [7, 1], [8, 1], [9, 1], [13, 1], [17, 1], [21, 1], [24, 1], [25, 1], [30, 1], [31, 1], [32, 1], [33, 1], [34, 1]]\n",
      "---\n",
      "{'15': 2, '26': 3, '4': 3, '2': 2, '17': 3, '1': 4}\n",
      "#####\n",
      "[[1, 1], [6, 1], [7, 1], [9, 1], [13, 1], [17, 1], [21, 1], [24, 1], [25, 1], [30, 1], [31, 1], [32, 1], [33, 1], [34, 1]]\n",
      "---\n",
      "{'14': 0}\n",
      "#####\n",
      "[[1, 1], [3, 1], [6, 1], [7, 1], [9, 1], [10, 1], [13, 1], [17, 1], [21, 1], [24, 1], [25, 1], [31, 1], [32, 1], [33, 1], [34, 1]]\n",
      "---\n",
      "{'23': 5, '5': 1, '17': 4, '4': 4}\n",
      "#####\n",
      "[[0, 1], [1, 1], [3, 1], [6, 1], [7, 1], [8, 1], [9, 1], [13, 1], [17, 1], [21, 1], [24, 1], [25, 1], [31, 1], [32, 1], [33, 1], [34, 1]]\n",
      "---\n",
      "{'14': 2, '20': 2, '4': 4, '2': 1, '5': 3, '25': 4, '16': 2, '10': 3, '1': 2}\n"
     ]
    }
   ],
   "source": [
    "#regresssion model\n",
    "wrong_predict = 0\n",
    "au_score = []\n",
    "for data in svm_testing_data:\n",
    "    print('#####')\n",
    "    local_wrong_predict = 0\n",
    "    local_accurate_predict = 0\n",
    "    tmp = []\n",
    "    predict = []\n",
    "    \n",
    "    for vector in data.landmark:\n",
    "        tmp.append(vector[0])\n",
    "        tmp.append(vector[1])\n",
    "        \n",
    "    for model in models:\n",
    "        if(model.predict([tmp]) != -1):\n",
    "#             predict.append([facs[models.index(model)],data.facs[str(facs[models.index(model)])] , model.predict([tmp])])\n",
    "            predict.append([models.index(model), model.predict([tmp])[0]])\n",
    "            #print(facs[models.index(model)])\n",
    "            if(str(facs[models.index(model)]) not in data.facs):\n",
    "                local_wrong_predict += 1\n",
    "            else: \n",
    "                local_accurate_predict += 1\n",
    "        else:\n",
    "            if(str(facs[models.index(model)]) in data.facs):\n",
    "                local_wrong_predict += 1\n",
    "    print(predict)\n",
    "#     print(local_accurate_predict)\n",
    "    au_score.append(float(local_accurate_predict)/float(len(data.facs)))\n",
    "    print(\"---\")\n",
    "    print(data.facs)\n",
    "    wrong_predict += local_wrong_predict\n",
    "    \n",
    "# print(wrong_predict)\n",
    "# print(sum(au_score)/float(len(au_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====\n",
      "[-1  2  2  2  2  2  2  2  2  2 -1 -1  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2 -1 -1  2]\n",
      "==\n",
      "[-1, -1, -1, -1, -1, -1, 2, -1, 2, 2, -1, -1, 3, -1, -1, -1, -1, -1, 2, 1, -1, 2, -1, -1, 4, 4, -1, -1, 2]\n",
      "=====\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "==\n",
      "[-1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 1, -1, -1, -1, -1, 4, 2, -1, -1, 1]\n",
      "=====\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1]\n",
      "==\n",
      "[-1, -1, -1, -1, -1, -1, 1, 3, 3, 4, 3, -1, 4, 4, -1, 3, 2, -1, 2, 2, -1, 2, -1, -1, 2, 3, -1, 4, 4]\n",
      "=====\n",
      "[2 0 0 2 2 0 0 2 2 2 2 2 2 0 2 2 2 2 0 2 2 0 2 2 0 2 2 2 2]\n",
      "==\n",
      "[-1, -1, -1, -1, -1, -1, -1, 1, 4, -1, 3, -1, 3, 2, -1, -1, 3, -1, 4, -1, -1, -1, 2, -1, 4, -1, -1, 1, 3]\n",
      "=====\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1]\n",
      "==\n",
      "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1]\n",
      "=====\n",
      "[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "==\n",
      "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1]\n",
      "=====\n",
      "[ 4 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  4 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1  4 -1]\n",
      "==\n",
      "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
      "=====\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1]\n",
      "==\n",
      "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3]\n",
      "=====\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "==\n",
      "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
      "=====\n",
      "[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "==\n",
      "[2, 1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
      "=====\n",
      "[-1  4  4  4  4  4  4 -1 -1  4 -1 -1  4  4 -1 -1 -1  4  4  4  4  4  4  4\n",
      "  4 -1 -1  4 -1]\n",
      "==\n",
      "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
      "=====\n",
      "[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "==\n",
      "[2, 2, 0, 2, 2, 2, -1, -1, 2, -1, -1, 0, 2, -1, 0, -1, -1, 0, 2, -1, 0, -1, -1, 0, -1, -1, 0, -1, 2]\n",
      "=====\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "==\n",
      "[-1, -1, -1, -1, -1, -1, 2, 1, -1, 2, -1, -1, -1, -1, -1, 3, 2, -1, -1, 1, -1, 3, -1, -1, -1, 2, -1, -1, -1]\n",
      "=====\n",
      "[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "==\n",
      "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2]\n",
      "=====\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1]\n",
      "==\n",
      "[-1, -1, -1, -1, 3, 2, 2, 3, 1, 3, 2, -1, -1, 2, -1, 1, 2, -1, 1, 2, -1, 4, 4, -1, -1, 3, -1, 4, -1]\n",
      "=====\n",
      "[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "==\n",
      "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
      "=====\n",
      "[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "==\n",
      "[-1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, 3, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, 3, -1, -1, -1, 2]\n",
      "=====\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "==\n",
      "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
      "=====\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1]\n",
      "==\n",
      "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
      "=====\n",
      "[-1 -1 -1  4  4  4 -1 -1 -1 -1 -1 -1 -1 -1  4  4 -1 -1  4 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1]\n",
      "==\n",
      "[-1, -1, -1, -1, -1, -1, 3, 3, -1, -1, 5, -1, -1, 4, -1, -1, 3, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, 5, -1]\n",
      "=====\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1]\n",
      "==\n",
      "[2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
      "=====\n",
      "[3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 4 4 3]\n",
      "==\n",
      "[-1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, 2, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, 1, -1, -1, -1, 4]\n",
      "=====\n",
      "[4 5 5 5 5 5 5 5 5 5 4 4 4 5 5 4 4 5 5 5 5 5 5 5 5 5 4 4 5]\n",
      "==\n",
      "[-1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1]\n",
      "=====\n",
      "[-1 -1  0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  0 -1 -1 -1 -1  0 -1 -1 -1 -1 -1\n",
      "  0 -1 -1 -1 -1]\n",
      "==\n",
      "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
      "=====\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "==\n",
      "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
      "=====\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "==\n",
      "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
      "=====\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1]\n",
      "==\n",
      "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
      "=====\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1]\n",
      "==\n",
      "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
      "=====\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1]\n",
      "==\n",
      "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, 2, 2, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1]\n",
      "=====\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1]\n",
      "==\n",
      "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
      "=====\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "==\n",
      "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
      "=====\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "==\n",
      "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
      "=====\n",
      "[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "==\n",
      "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
      "=====\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "==\n",
      "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
      "=====\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "==\n",
      "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
      "=====\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1]\n",
      "==\n",
      "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n"
     ]
    }
   ],
   "source": [
    "#get predict result\n",
    "y_label = []\n",
    "for au in facs:\n",
    "    x_training = []\n",
    "    y_label_tmp = []\n",
    "    #create label array\n",
    "    for data in svm_testing_data:\n",
    "        if(str(au) in data.facs):\n",
    "#             if(data.facs[str(au)] == 0):\n",
    "#                 y_label.append(2)\n",
    "#             else:\n",
    "            y_label_tmp.append(data.facs[str(au)])\n",
    "#             y_label.append(1)\n",
    "        else:\n",
    "            y_label_tmp.append(-1)\n",
    "        #create training data: 1x68 array, result of PCA process\n",
    "        vector = []\n",
    "        for tmp in data.landmark:\n",
    "            vector.append(tmp[0])\n",
    "            vector.append(tmp[1])\n",
    "        x_training.append(vector)\n",
    "    y_label.append(y_label_tmp)\n",
    "for model in models:\n",
    "    print(\"=====\")\n",
    "    print(model.predict(x_training))\n",
    "    print(\"==\")\n",
    "    print(y_label[models.index(model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build rule-based system\n",
    "#emotion class have name = str, criteria = function, facs required = [[]], caculate score of input\n",
    "class Emotion:\n",
    "    def __init__(self, name, facs_required, criteria):\n",
    "        self.name = name\n",
    "        self.facs_required = facs_required\n",
    "        self.criteria = criteria\n",
    "    \n",
    "    def criteria(self, facs_input):\n",
    "        return True\n",
    "    \n",
    "    def score(self,facs_input = []):\n",
    "        if(self.criteria(facs_input) == True):\n",
    "            max = 0\n",
    "            for required in self.facs_required:\n",
    "                au_count = 0\n",
    "                for facs in facs_input:\n",
    "                    if facs in required:\n",
    "                        au_count += 1\n",
    "                if au_count/float(len(required)) >= max:\n",
    "                    max = au_count/float(len(required))\n",
    "            return max\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "def angry_criteria(facs_input):\n",
    "    if(23 in facs_input):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def disgus_criteria(facs_input):\n",
    "    if(9 in facs_input or 10 in facs_input):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def fear_criteria(facs_input):\n",
    "    if(1 in facs_input and 2 in facs_input and 3 in facs_input):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def surprise_criteria(facs_input):\n",
    "    if(1 in facs_input and 2 in facs_input):\n",
    "        return True\n",
    "    if(5 in facs_input):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def sadness_criteria(facs_input):\n",
    "    return True\n",
    "\n",
    "def happy_criteria(facs_input):\n",
    "    if(12 in facs_input):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def contempt_criteria(facs_input):\n",
    "    if(14 in facs_input):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "happy = Emotion('happy', [[6,12]], happy_criteria)\n",
    "sadness = Emotion('sadness', [[1,4,5], [6,15], [1,4,15]], sadness_criteria)\n",
    "surprise = Emotion('surprise', [[1,2,5,26]], surprise_criteria)\n",
    "fear = Emotion('fear', [[1,2,4,5,7,20,26]], fear_criteria)\n",
    "angry = Emotion('angry', [[4,5,7,23]], angry_criteria)\n",
    "disgust = Emotion('disgust', [[9,15,16], [10,15,16]], disgus_criteria)\n",
    "contempt = Emotion('contempt', [[12,14]], contempt_criteria)\n",
    "\n",
    "emotions = [happy, sadness, surprise, fear, angry, disgust, contempt]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996336996337\n"
     ]
    }
   ],
   "source": [
    "#emotion task - build training data\n",
    "result = []\n",
    "x_training = []\n",
    "y_label = []\n",
    "\n",
    "emotions = []\n",
    "for data in svm_training_data:\n",
    "    if(data.emotion != -1):\n",
    "        tmp = []\n",
    "        for vector in data.landmark:\n",
    "            tmp.append(vector[0])\n",
    "            tmp.append(vector[1])\n",
    "        x_training.append(tmp)\n",
    "        y_label.append(data.emotion)\n",
    "        if(data.emotion not in emotions):\n",
    "            emotions.append(data.emotion)\n",
    "emotions.sort()\n",
    "\n",
    "clf = svm.LinearSVC()\n",
    "clf.fit(normalize(x_training, norm='max', axis=0), y_label)\n",
    "print(clf.score(normalize(x_training, norm='max', axis=0), y_label))\n",
    "# print(x_training[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[3, 7, 1, 5, 7, 6, 4, 1, 3, 5, 7, 6, 1, 5, 7, 1, 3, 7, 6, 1, 5, 7, 1, 4, 3, 5, 7, 3, 5, 7, 6, 1, 5, 6, 7, 4, 3, 4, 7, 1, 5, 4, 7, 3, 4, 7, 5, 6, 2, 2, 2, 2, 2, 2]\n",
      "0.111111111111\n"
     ]
    }
   ],
   "source": [
    "#emotion task - multiclass SVM\n",
    "\n",
    "#normalize using 2 set as base\n",
    "def coopNormalize(set1, set2):\n",
    "    len1 = len(set1)\n",
    "    len2 = len(set2)\n",
    "    merged = set1 + set2\n",
    "    normalized = normalize(merged, norm='max', axis=0)\n",
    "    result = []\n",
    "    for i in range(len1, len1 + len2):\n",
    "        result.append(normalized[i])\n",
    "    return result\n",
    "\n",
    "\n",
    "x_testing = []\n",
    "y_label = []\n",
    "for data in svm_testing_data:\n",
    "    if(data.emotion != -1):\n",
    "        tmp = []\n",
    "        for vector in data.landmark:\n",
    "            tmp.append(vector[0])\n",
    "            tmp.append(vector[1])\n",
    "        x_testing.append(tmp)\n",
    "        y_label.append(data.emotion)\n",
    "\n",
    "print(clf.predict(coopNormalize(x_training, x_testing)))\n",
    "print(y_label)\n",
    "print(clf.score(coopNormalize(x_training, x_testing), y_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict([coopNormalize(x_training, x_testing)[21]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n"
     ]
    }
   ],
   "source": [
    "data_normalize = x_training + x_testing\n",
    "landmark = [-2.6980930928635729, -0.31857955010475081, -2.4350712086726105, -0.32509667104587692, -2.4298610239616778, -0.35955207872170547, -2.1811436683827026, -0.28568767922696026, -1.9174666553812187, -0.20775041201777356, -2.7972784737445693, 1.1049142994780965, -2.9224991625867744, 1.3277957830916023, -1.23534760148749, 0.57934014892410346, -1.225183463165763, 0.82741473408228217, -3.3194317944334557, 0.1814099208488642, -4.8558478954794566, -0.36411945838878523, -5.2758224234044633, -0.82203783382576034, -4.2510266855160239, 0.049837009428216561, -2.9651567587876286, 3.4990404561355035, -2.9068832215120324, 2.0883269243263953, -2.7085528331971034, 1.7785721806339154, -2.7003767639251492, 1.778681892849761, -4.6190237758178228, 0.11972084774628655, -1.9490443023060706, 1.407556580458774, -0.11077651536596278, 1.3682180209973325, 1.0794218391341062, 0.96527008383105795, 4.3776095950579901, -1.1732056002104656, 8.5521781483821044, -1.199075533661528, 2.846780143311662, -2.6060924446163085, 0.51302708302110034, -1.5538071429818672, -3.0490022692612229, 0.26795765211662115, -3.0565040467313978, 1.5710547321875765, 0.79108954431237066, 1.6543582482893555, 0.86348226936199524, 1.0090661697904295, 0.96883851764948759, 0.89810161923134046, 1.231480734940277, -1.3355214740307133, -8.4468236045526908, -0.4018420536284566, -6.3486402132396904, -0.6535604934111916, -4.6157119253143435, -0.19689573283642403, -5.386747635136345, 1.2457653997253999, -7.7001183372715616, 1.8722125818182178, -2.7730024729577565, 0.1157438485094815, -1.8280778448305739, -1.2550505270286436, -0.5529301349515805, -2.5138494046385347, -4.4533456970056449, -1.9497642314426429, -5.8972053670511855, -1.2075327237360938, -6.2184925722695255, -0.44737470439973492, -3.7184704204775016, 3.7488370556929738, 0.058742349601686783, 5.4159598619234259, -0.82098315798390331, 4.5569615577092861, -3.0057697290332186, 4.0877720165825053, -6.8405786883978976, 3.3150975405698375, -7.6759418092206317, 3.5538767153158233, -6.2551285551713818, 0.53728256296038523, -8.7567126293202762, -2.1339225464851239, -6.1233027881500277, -0.6247115750235821, -5.2582065938950677, -0.57964158684944778, -4.5458511553240157, -0.27849336784350953, -6.9494726684200998, 0.62455353456283547, -5.1592124896214102, -1.4037405707540529, -4.5364659163077761, 0.10915270188979775, -4.4167421622358063, 0.39365236508919565, -5.3943783120719502, 0.57348173934451552, -5.8927703205571333, 0.29622284461811432, -5.7403598183086615, 0.061724813771192544, -5.1225942885987479, 0.42635986120272662, -5.1167896441550909, 0.31543715944505379, -5.5286969778268542, -0.20170118247034452, -4.7883353208642063, -0.68784555820707283, -4.7914262610444212, -1.0457930644805629, -4.7945313209947074, -0.5644573524716634, -5.9035109186196166, 0.17287507243844402, -5.128391838400205, 0.49177727042172137]\n",
    "print(clf.predict([coopNormalize(data_normalize, [landmark])[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "# save_object(models, 'models/au_models.pkl')\n",
    "#save_object(facs, '/Programing/GR/Code/Python/models/facs.pkl')\n",
    "# save_object(clf, 'models/emotion_model.pkl')\n",
    "save_object(x_training + x_testing, 'models/normalize_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create json log file\n",
    "import json\n",
    "log_path = '/Programing/GR/Code/Python/log/'\n",
    "import time\n",
    "import json\n",
    "ts = int(time.time())\n",
    "#jsonAdder = json.dumps()\n",
    "output = {'n_train': len(training_images), 'n_test': len(testing_images), 'au_score' : au_models_score, 'facs': facs }\n",
    "#print json.dumps(output, sort_keys=True, indent=4, separators=(',', ': '))\n",
    "with open(log_path + 'system_log' + str(ts) + '.txt', \"w+\") as outfile:\n",
    "    json.dump(output, outfile,sort_keys=True, indent=4, separators=(',', ': '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
